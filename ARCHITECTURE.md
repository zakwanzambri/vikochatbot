# ğŸ”„ System Architecture & Data Flow

## ğŸ“Š High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     USER INTERFACE (Streamlit)              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ Upload Files â”‚  â”‚  Chat Input  â”‚  â”‚   Database   â”‚     â”‚
â”‚  â”‚   (Sidebar)  â”‚  â”‚   (Main)     â”‚  â”‚  Management  â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                  â”‚                  â”‚
          â–¼                  â–¼                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      PROCESSING LAYER                        â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚            DOCUMENT PROCESSING PIPELINE              â”‚  â”‚
â”‚  â”‚                                                       â”‚  â”‚
â”‚  â”‚  1. Document Upload                                  â”‚  â”‚
â”‚  â”‚     â†“                                                â”‚  â”‚
â”‚  â”‚  2. Text Extraction (PDF/DOCX/TXT)                  â”‚  â”‚
â”‚  â”‚     â†“                                                â”‚  â”‚
â”‚  â”‚  3. Text Chunking (Smart Splitting)                 â”‚  â”‚
â”‚  â”‚     â†“                                                â”‚  â”‚
â”‚  â”‚  4. Embedding Generation (OpenAI)                   â”‚  â”‚
â”‚  â”‚     â†“                                                â”‚  â”‚
â”‚  â”‚  5. Vector Storage (FAISS/ChromaDB)                 â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚               QUERY PROCESSING PIPELINE              â”‚  â”‚
â”‚  â”‚                                                       â”‚  â”‚
â”‚  â”‚  1. User Question                                    â”‚  â”‚
â”‚  â”‚     â†“                                                â”‚  â”‚
â”‚  â”‚  2. Question Embedding (OpenAI)                     â”‚  â”‚
â”‚  â”‚     â†“                                                â”‚  â”‚
â”‚  â”‚  3. Semantic Search (Vector DB)                     â”‚  â”‚
â”‚  â”‚     â†“                                                â”‚  â”‚
â”‚  â”‚  4. Context Retrieval (Top-K Chunks)                â”‚  â”‚
â”‚  â”‚     â†“                                                â”‚  â”‚
â”‚  â”‚  5. LLM Generation (GPT-4 + Context)                â”‚  â”‚
â”‚  â”‚     â†“                                                â”‚  â”‚
â”‚  â”‚  6. Answer with Citations                            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      STORAGE LAYER                           â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   Uploads    â”‚  â”‚  Vector DB   â”‚  â”‚   Session    â”‚      â”‚
â”‚  â”‚   (Files)    â”‚  â”‚ (Embeddings) â”‚  â”‚    State     â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    EXTERNAL SERVICES                         â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              OpenAI API                               â”‚  â”‚
â”‚  â”‚  â€¢ text-embedding-3-small (Embeddings)               â”‚  â”‚
â”‚  â”‚  â€¢ gpt-4o / gpt-4-turbo (Chat Completion)           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”„ Detailed Data Flow

### ğŸ“¤ Document Upload Flow

```
User Action: Upload PDF/DOCX/TXT
    â†“
Save to: data/uploads/filename.ext
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Document Extraction            â”‚
â”‚  â€¢ PDFExtractor (PyMuPDF)      â”‚
â”‚  â€¢ DOCXExtractor (python-docx) â”‚
â”‚  â€¢ TextExtractor (chardet)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
    Extracted Text String
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Text Chunking                  â”‚
â”‚  â€¢ Size: 1000 chars            â”‚
â”‚  â€¢ Overlap: 200 chars          â”‚
â”‚  â€¢ Smart boundaries            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
    List of Text Chunks
    [chunk1, chunk2, ...]
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Embedding Generation           â”‚
â”‚  â€¢ Model: text-embedding-3-smallâ”‚
â”‚  â€¢ Dimension: 1536             â”‚
â”‚  â€¢ Batch processing            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
    Chunks + Embeddings
    [{text, embedding, metadata}]
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Vector Storage                 â”‚
â”‚  â€¢ FAISS: IndexFlatL2          â”‚
â”‚  â€¢ ChromaDB: Persistent        â”‚
â”‚  â€¢ Metadata: filename, etc     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
    Stored in Vector Database
    âœ… Ready for Queries
```

### ğŸ’¬ Question-Answer Flow

```
User Action: Type Question
    â†“
    "What is the main topic?"
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Query Embedding                â”‚
â”‚  â€¢ Convert to 1536-dim vector  â”‚
â”‚  â€¢ Same model as docs          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
    Query Vector [0.123, -0.456, ...]
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Similarity Search              â”‚
â”‚  â€¢ Compare with all doc chunks â”‚
â”‚  â€¢ Calculate cosine similarity â”‚
â”‚  â€¢ Rank by relevance           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
    Top-5 Most Similar Chunks
    [chunk1(0.92), chunk2(0.87), ...]
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Context Formatting             â”‚
â”‚  â€¢ Add source citations        â”‚
â”‚  â€¢ Format for LLM              â”‚
â”‚  â€¢ Limit token count           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
    Formatted Context String
    "[Source 1: doc.pdf]
     Content here..."
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLM Completion                 â”‚
â”‚  â€¢ Model: GPT-4o               â”‚
â”‚  â€¢ Temperature: 0.3            â”‚
â”‚  â€¢ System: RAG instructions    â”‚
â”‚  â€¢ Input: Question + Context   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
    Generated Answer
    "Based on the documents..."
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Response Formatting            â”‚
â”‚  â€¢ Extract answer              â”‚
â”‚  â€¢ List sources                â”‚
â”‚  â€¢ Show relevance scores       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
    Display to User
    âœ… Answer + Sources + Scores
```

## ğŸ§© Component Interactions

### Document Processor â†” Embedder
```python
# Extract text
extractor = PDFExtractor()
data = extractor.extract_text("doc.pdf")
text = data['text']

# Pass to chunker
chunker = TextChunker()
chunks = chunker.chunk_text(text, metadata={'filename': 'doc.pdf'})

# Generate embeddings
embedder = OpenAIEmbedder()
embedded_chunks = embedder.embed_chunks(chunks)
```

### Vector Store â†” Retriever
```python
# Store embeddings
vector_store = FAISSVectorStore()
vector_store.add_documents(embedded_chunks)

# Later: Retrieve similar documents
retriever = DocumentRetriever(vector_store, embedder)
results = retriever.retrieve("user question")
```

### Retriever â†” ChatBot
```python
# Retrieve context
retriever = DocumentRetriever(vector_store, embedder)
retrieved_chunks = retriever.retrieve(question, top_k=5)
context = retriever.format_context(retrieved_chunks)

# Generate answer
chatbot = ChatBot()
answer = chatbot.chat(question, context)
```

## ğŸ“Š Module Dependencies

```
streamlit_app.py
    â†“ imports
    â”œâ”€â†’ config.py (settings)
    â”œâ”€â†’ document_processor (extract text)
    â”‚   â”œâ”€â†’ pdf_extractor.py
    â”‚   â”œâ”€â†’ docx_extractor.py
    â”‚   â””â”€â†’ text_extractor.py
    â”œâ”€â†’ embedding (chunk & embed)
    â”‚   â”œâ”€â†’ chunker.py
    â”‚   â””â”€â†’ embedder.py (â†’ OpenAI API)
    â”œâ”€â†’ vector_store (storage)
    â”‚   â”œâ”€â†’ faiss_store.py (â†’ FAISS)
    â”‚   â””â”€â†’ chroma_store.py (â†’ ChromaDB)
    â”œâ”€â†’ retrieval (search)
    â”‚   â””â”€â†’ retriever.py
    â””â”€â†’ llm (chat)
        â””â”€â†’ chat_completion.py (â†’ OpenAI API)
```

## ğŸ” API Call Flow

```
Application Start
    â†“
Load API Key from .env
    â†“
Initialize OpenAI Client
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         EMBEDDING CALLS             â”‚
â”‚  Document Processing:               â”‚
â”‚    â€¢ ~10-50 calls per document     â”‚
â”‚    â€¢ Batch processing (100/batch)  â”‚
â”‚    â€¢ Cost: ~$0.00002 per 1K tokens â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
    Store embeddings locally
    (No more API calls until new docs)
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           QUERY CALLS               â”‚
â”‚  Per Question:                      â”‚
â”‚    â€¢ 1 embedding call (question)   â”‚
â”‚    â€¢ 1 chat completion call        â”‚
â”‚    â€¢ Cost: ~$0.01-0.05 per Q       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ’¾ Storage Organization

```
data/
â”œâ”€â”€ uploads/                    # User uploaded files
â”‚   â”œâ”€â”€ document1.pdf
â”‚   â”œâ”€â”€ document2.docx
â”‚   â””â”€â”€ notes.txt
â”‚
â””â”€â”€ vector_db/                  # Vector database
    â”œâ”€â”€ faiss_index.index      # FAISS index file
    â”œâ”€â”€ faiss_index.pkl        # FAISS metadata
    â”‚
    â””â”€â”€ chroma/                # ChromaDB directory
        â”œâ”€â”€ chroma.sqlite3
        â””â”€â”€ [collection files]
```

## ğŸ”„ Session State (Streamlit)

```python
st.session_state = {
    'vector_store': FAISSVectorStore,      # Active vector DB
    'retriever': DocumentRetriever,        # Search engine
    'chatbot': ChatBot,                    # LLM interface
    'chat_history': [                      # Conversation
        {'role': 'user', 'content': '...'},
        {'role': 'assistant', 'content': '...', 'sources': [...]}
    ],
    'documents_loaded': True,              # Ready status
    'processed_files': ['doc1.pdf', ...]   # Uploaded files
}
```

## âš¡ Performance Characteristics

### Time Complexity
| Operation | Time | Notes |
|-----------|------|-------|
| PDF Extraction | O(n) | n = pages |
| Text Chunking | O(n) | n = chars |
| Embedding (1 text) | ~100ms | API latency |
| Embedding (batch) | ~500ms | 100 texts |
| Vector Add | O(1) | Per vector |
| Vector Search | O(n) | n = stored vectors |
| LLM Completion | ~2-5s | API latency |

### Space Complexity
| Component | Space | Notes |
|-----------|-------|-------|
| 1 Document (100 pages) | ~500KB | Text |
| 1 Chunk | ~1KB | Text |
| 1 Embedding | ~6KB | 1536 floats |
| 100 Documents | ~600MB | Vectors |

## ğŸ” Error Handling Flow

```
User Action
    â†“
Try Operation
    â†“
    â”œâ”€â†’ Success
    â”‚   â””â”€â†’ Continue
    â”‚
    â””â”€â†’ Error
        â†“
        â”œâ”€â†’ File Error
        â”‚   â””â”€â†’ Show: "Invalid file format"
        â”‚
        â”œâ”€â†’ API Error
        â”‚   â””â”€â†’ Show: "API key invalid"
        â”‚
        â”œâ”€â†’ Processing Error
        â”‚   â””â”€â†’ Show: "Failed to process document"
        â”‚
        â””â”€â†’ General Error
            â””â”€â†’ Show: Error message + suggestion
```

## ğŸ¯ Key Decision Points

### 1. Which Vector Store?
```
FAISS:
âœ… Faster search
âœ… Less disk space
âŒ Manual persistence

ChromaDB:
âœ… Auto-persistence
âœ… More features
âŒ Slightly slower
```

### 2. Which Embedding Model?
```
text-embedding-3-small:
âœ… Fast
âœ… Cheap ($0.00002/1K)
âœ… Good quality

text-embedding-3-large:
âœ… Better quality
âŒ 2x more expensive
âŒ Slower
```

### 3. Which Chat Model?
```
GPT-4o:
âœ… Best quality
âœ… Latest model
âŒ Most expensive

GPT-4-turbo:
âœ… Fast
âœ… Good quality
âœ… Cheaper than GPT-4o

GPT-3.5-turbo:
âœ… Very cheap
âœ… Very fast
âŒ Lower quality
```

---

**This architecture provides a scalable, maintainable, and efficient RAG system! ğŸš€**
